# ğŸ¯ Multivariate Polynomial Regression

## ğŸ“– Table of Contents

<details>
<summary>Click to expand</summary>

- [ğŸ¯ Multivariate Polynomial Regression](#-multivariate-polynomial-regression)
  - [ğŸ“– Table of Contents](#-table-of-contents)
  - [âœ¨ Features](#-features)
  - [ğŸ§  Algorithm Overview](#-algorithm-overview)
    - [How It Works](#how-it-works)
    - [Mathematical Foundation](#mathematical-foundation)
  - [ğŸš€ Quick Start](#-quick-start)
  - [ğŸ“š API Reference](#-api-reference)
    - [Main Class: `MultivariatePolynomialRegression`](#main-class-multivariatepolynomialregression)
      - [Constructor](#constructor)
      - [Methods](#methods)
    - [Configuration Builder](#configuration-builder)
    - [Interfaces](#interfaces)
  - [âš™ï¸ Parameter Optimization Guide](#ï¸-parameter-optimization-guide)
    - [1. `polynomialDegree` ğŸ“](#1-polynomialdegree-)
    - [2. `learningRate` ğŸ“ˆ](#2-learningrate-)
    - [3. `learningRateDecay` ğŸ“‰](#3-learningratedecay-)
    - [4. `momentum` ğŸƒ](#4-momentum-)
    - [5. `normalizationMethod` ğŸ“Š](#5-normalizationmethod-)
    - [6. `regularization` ğŸ›¡ï¸](#6-regularization-ï¸)
    - [7. `gradientClipValue` âœ‚ï¸](#7-gradientclipvalue-ï¸)
    - [8. `confidenceLevel` ğŸ¯](#8-confidencelevel-)
    - [9. `batchSize` ğŸ“¦](#9-batchsize-)
  - [ğŸ® Real-World Examples](#-real-world-examples)
    - [Example 1: Stock Price Prediction](#example-1-stock-price-prediction)
    - [Example 2: Sensor Calibration](#example-2-sensor-calibration)
    - [Example 3: Real-Time IoT Data Processing](#example-3-real-time-iot-data-processing)
  - [ğŸ“Š Performance Optimization](#-performance-optimization)
    - [Memory Efficiency](#memory-efficiency)
    - [Computational Efficiency](#computational-efficiency)
    - [Recommended Configurations by Use Case](#recommended-configurations-by-use-case)
  - [ğŸ”§ Advanced Usage](#-advanced-usage)
    - [Custom Normalization Strategies](#custom-normalization-strategies)
    - [Model Serialization](#model-serialization)
    - [Monitoring Training Progress](#monitoring-training-progress)
  - [ğŸ› Troubleshooting](#-troubleshooting)
  - [ğŸ—ï¸ Architecture](#ï¸-architecture)
  - [ğŸ“ˆ Benchmarks](#-benchmarks)
  - [ğŸ¤ Contributing](#-contributing)
  - [ğŸ“„ License](#-license)
  - [ğŸ™ Acknowledgments](#-acknowledgments)

</details>

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ”„ Online Learning

Process data points **one at a time** without storing the entire dataset.
Perfect for:

- ğŸ“¡ Real-time sensor data
- ğŸ“Š Streaming analytics
- ğŸ’¾ Memory-constrained environments

</td>
<td width="50%">

### ğŸ“ˆ Polynomial Features

Automatically expand features to capture **non-linear relationships**:

- Linear, quadratic, cubic, and higher
- All interaction terms included
- Configurable degree (1 to N)

</td>
</tr>
<tr>
<td width="50%">

### âš¡ Momentum-Based SGD

Fast convergence with **velocity accumulation**:

- Smooth gradient updates
- Escape local minima
- Configurable momentum coefficient

</td>
<td width="50%">

### ğŸ¯ Confidence Intervals

Quantify **prediction uncertainty**:

- T-distribution for small samples
- Z-distribution for large samples
- Configurable confidence levels

</td>
</tr>
<tr>
<td width="50%">

### ğŸ›¡ï¸ Regularization

Prevent **overfitting** with L2 regularization:

- Weight decay
- Improved generalization
- Configurable strength

</td>
<td width="50%">

### ğŸ“Š Multiple Normalizations

Three **normalization strategies**:

- Min-Max scaling [0, 1]
- Z-Score standardization
- None (raw features)

</td>
</tr>
<tr>
<td width="50%">

### âœ‚ï¸ Gradient Clipping

**Numerical stability** guaranteed:

- Prevents exploding gradients
- Configurable clip threshold
- Stable training dynamics

</td>
<td width="50%">

### ğŸ“‰ Learning Rate Decay

**Automatic annealing** for convergence:

- Exponential decay
- Per-sample adjustment
- Fine-tuned final weights

</td>
</tr>
</table>

---

## ğŸ§  Algorithm Overview

### How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ONLINE LEARNING PIPELINE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Input   â”‚â”€â”€â”€â–¶â”‚  Normalize    â”‚â”€â”€â”€â–¶â”‚  Generate Poly   â”‚â”€â”€â”€â–¶â”‚  Predict â”‚ â”‚
â”‚  â”‚  x = [xâ‚,xâ‚‚]  â”‚  [0,1] or z   â”‚    â”‚  Features Ï†      â”‚    â”‚  Å· = wáµ€Ï† â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                      â”‚      â”‚
â”‚                                                                      â–¼      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Update  â”‚â—€â”€â”€â”€â”‚   Momentum    â”‚â—€â”€â”€â”€â”‚  Compute         â”‚â—€â”€â”€â”€â”‚  Error   â”‚ â”‚
â”‚  â”‚  Weights â”‚    â”‚   v=Î¼v+Î·g     â”‚    â”‚  Gradient        â”‚    â”‚  e=y-Å·   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Mathematical Foundation

<details>
<summary><b>ğŸ“ Polynomial Feature Expansion</b></summary>

For an input vector **x** = [xâ‚, xâ‚‚] with degree _d_ = 2:

```
Ï†(x) = [1, xâ‚, xâ‚‚, xâ‚Â², xâ‚xâ‚‚, xâ‚‚Â²]
```

**Feature Count Formula:**

$$\text{features} = \binom{n + d}{d} = \frac{(n + d)!}{d! \cdot n!}$$

| Input Dimensions | Degree | Feature Count |
| :--------------: | :----: | :-----------: |
|        2         |   2    |       6       |
|        2         |   3    |      10       |
|        3         |   2    |      10       |
|        3         |   3    |      20       |
|        5         |   2    |      21       |
|        5         |   3    |      56       |

</details>

<details>
<summary><b>ğŸ“‰ Stochastic Gradient Descent with Momentum</b></summary>

**For each sample (x, y):**

1. **Forward Pass:** $$\hat{y} = \mathbf{w}^T \cdot \phi(\mathbf{x})$$

2. **Error Computation:** $$e = y - \hat{y}$$

3. **Gradient with Regularization:**
   $$\mathbf{g} = -e \cdot \phi(\mathbf{x}) + \lambda \cdot \mathbf{w}$$

4. **Gradient Clipping:** $$\mathbf{g} = \text{clip}(\mathbf{g}, -c, c)$$

5. **Velocity Update:**
   $$\mathbf{v} = \mu \cdot \mathbf{v} + \eta \cdot \mathbf{g}$$

6. **Weight Update:** $$\mathbf{w} = \mathbf{w} - \mathbf{v}$$

7. **Learning Rate Decay:** $$\eta = \eta \times \text{decay}$$

</details>

<details>
<summary><b>ğŸ“Š Confidence Interval Calculation</b></summary>

**Prediction Interval:** $$\hat{y} \pm t_{\alpha/2} \times SE$$

**Standard Error:**
$$SE = \sqrt{\sigma^2 \times \left(1 + \frac{1}{n} + h\right)}$$

Where:

- $\sigma^2$ = residual variance
- $n$ = sample count
- $h$ = leverage â‰ˆ $\|\phi\|^2 / n$
- $t_{\alpha/2}$ = critical value from t-distribution

</details>

<details>
<summary><b>ğŸ“ˆ Model Quality Metrics</b></summary>

**R-Squared (Coefficient of Determination):**
$$R^2 = 1 - \frac{SS_{res}}{SS_{tot}} = 1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}$$

|  RÂ² Value   | Interpretation |
| :---------: | :------------- |
| 0.90 - 1.00 | Excellent fit  |
| 0.70 - 0.89 | Good fit       |
| 0.50 - 0.69 | Moderate fit   |
| 0.00 - 0.49 | Poor fit       |

**RMSE (Root Mean Squared Error):**
$$RMSE = \sqrt{\frac{1}{n \times d} \sum_{i,j}(y_{ij} - \hat{y}_{ij})^2}$$

</details>

---

## ğŸš€ Quick Start

### Basic Usage

```typescript
import { MultivariatePolynomialRegression } from "jsr:@hviana/polynomial-regression";

// 1ï¸âƒ£ Create model with default settings
const model = new MultivariatePolynomialRegression();

// 2ï¸âƒ£ Train with data
model.fitOnline({
  xCoordinates: [
    [1, 2],
    [2, 3],
    [3, 4],
    [4, 5],
    [5, 6],
  ],
  yCoordinates: [
    [5],
    [13],
    [25],
    [41],
    [61],
  ],
});

// 3ï¸âƒ£ Make predictions
const result = model.predict({ futureSteps: 3 });

console.log("Predictions:", result.predictions);
console.log("RÂ²:", result.rSquared.toFixed(4));
console.log("RMSE:", result.rmse.toFixed(4));
```

### With Custom Configuration

```typescript
import {
  ConfigurationBuilder,
  MultivariatePolynomialRegression,
} from "jsr:@hviana/polynomial-regression";

// Use the builder pattern for clean configuration
const config = new ConfigurationBuilder()
  .withPolynomialDegree(3) // Cubic polynomial
  .withLearningRate(0.005) // Lower learning rate
  .withMomentum(0.95) // Higher momentum
  .withNormalizationMethod("z-score") // Z-score normalization
  .withRegularization(0.001) // Stronger regularization
  .withConfidenceLevel(0.99) // 99% confidence intervals
  .build();

const model = new MultivariatePolynomialRegression(config);
```

### Incremental Learning

```typescript
const model = new MultivariatePolynomialRegression();

// Train incrementally as data arrives
for (const dataPoint of dataStream) {
  model.fitOnline({
    xCoordinates: [dataPoint.features],
    yCoordinates: [dataPoint.target],
  });

  // Model is immediately updated and ready for predictions
  const prediction = model.predict({
    futureSteps: 0,
    inputPoints: [nextFeatures],
  });

  console.log(`Prediction: ${prediction.predictions[0].predicted}`);
}
```

---

## ğŸ“š API Reference

### Main Class: `MultivariatePolynomialRegression`

#### Constructor

```typescript
constructor(config?: Partial<IConfiguration>)
```

| Parameter | Type                      | Description                                                 |
| --------- | ------------------------- | ----------------------------------------------------------- |
| `config`  | `Partial<IConfiguration>` | Optional configuration object. Missing values use defaults. |

**Default Configuration:**

```typescript
{
  polynomialDegree: 2,
  enableNormalization: true,
  normalizationMethod: 'min-max',
  learningRate: 0.01,
  learningRateDecay: 0.999,
  momentum: 0.9,
  regularization: 1e-6,
  gradientClipValue: 1.0,
  confidenceLevel: 0.95,
  batchSize: 1
}
```

#### Methods

<details>
<summary><b><code>fitOnline(params)</code></b> - Train the model incrementally</summary>

```typescript
fitOnline(params: { 
  xCoordinates: number[][], 
  yCoordinates: number[][] 
}): void
```

**Parameters:**

| Name           | Type         | Description                                    |
| -------------- | ------------ | ---------------------------------------------- |
| `xCoordinates` | `number[][]` | Input samples, shape `[n_samples][n_features]` |
| `yCoordinates` | `number[][]` | Target values, shape `[n_samples][n_outputs]`  |

**Example:**

```typescript
// Single sample
model.fitOnline({
  xCoordinates: [[1.0, 2.0]],
  yCoordinates: [[5.0]],
});

// Batch of samples
model.fitOnline({
  xCoordinates: [[1, 2], [2, 3], [3, 4]],
  yCoordinates: [[5], [11], [19]],
});

// Multi-output regression
model.fitOnline({
  xCoordinates: [[1, 2], [2, 3]],
  yCoordinates: [[5, 10], [11, 22]],
});
```

**Throws:**

- `Error` if `xCoordinates` and `yCoordinates` have different lengths
- `Error` if dimensions change after initialization

</details>

<details>
<summary><b><code>predict(params)</code></b> - Generate predictions with confidence intervals</summary>

```typescript
predict(params: { 
  futureSteps: number, 
  inputPoints?: number[][] 
}): PredictionResult
```

**Parameters:**

| Name          | Type         | Description                                    |
| ------------- | ------------ | ---------------------------------------------- |
| `futureSteps` | `number`     | Number of future points to extrapolate         |
| `inputPoints` | `number[][]` | Optional specific input coordinates to predict |

**Returns:** `PredictionResult`

```typescript
interface PredictionResult {
  predictions: SinglePrediction[];
  confidenceLevel: number;
  rSquared: number;
  rmse: number;
  sampleCount: number;
  isModelReady: boolean;
}

interface SinglePrediction {
  predicted: number[];
  lowerBound: number[];
  upperBound: number[];
  standardError: number[];
}
```

**Example:**

```typescript
// Extrapolate 5 future steps
const result = model.predict({ futureSteps: 5 });

// Predict at specific points
const result = model.predict({
  futureSteps: 0,
  inputPoints: [[6, 7], [7, 8], [8, 9]],
});

// Access results
result.predictions.forEach((pred, i) => {
  console.log(`Point ${i}:`);
  console.log(`  Predicted: ${pred.predicted}`);
  console.log(`  95% CI: [${pred.lowerBound}, ${pred.upperBound}]`);
  console.log(`  Std Error: ${pred.standardError}`);
});
```

</details>

<details>
<summary><b><code>getModelSummary()</code></b> - Get current model state</summary>

```typescript
getModelSummary(): ModelSummary
```

**Returns:** `ModelSummary`

```typescript
interface ModelSummary {
  isInitialized: boolean;
  inputDimension: number;
  outputDimension: number;
  polynomialDegree: number;
  polynomialFeatureCount: number;
  sampleCount: number;
  rSquared: number;
  rmse: number;
  normalizationEnabled: boolean;
  normalizationMethod: string;
}
```

**Example:**

```typescript
const summary = model.getModelSummary();

console.log(`
ğŸ“Š Model Summary
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Initialized:    ${summary.isInitialized ? "âœ…" : "âŒ"}
Input Dims:     ${summary.inputDimension}
Output Dims:    ${summary.outputDimension}
Poly Degree:    ${summary.polynomialDegree}
Features:       ${summary.polynomialFeatureCount}
Samples:        ${summary.sampleCount}
RÂ²:             ${summary.rSquared.toFixed(4)}
RMSE:           ${summary.rmse.toFixed(4)}
Normalization:  ${summary.normalizationMethod}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
`);
```

</details>

<details>
<summary><b><code>getWeights()</code></b> - Get model weights</summary>

```typescript
getWeights(): number[][]
```

**Returns:** 2D array of weights, shape `[outputDimension][featureCount]`

**Example:**

```typescript
const weights = model.getWeights();

// For a 2D input with degree 2, features are:
// [1, xâ‚, xâ‚‚, xâ‚Â², xâ‚xâ‚‚, xâ‚‚Â²]
console.log("Bias:", weights[0][0]);
console.log("xâ‚ coefficient:", weights[0][1]);
console.log("xâ‚‚ coefficient:", weights[0][2]);
console.log("xâ‚Â² coefficient:", weights[0][3]);
console.log("xâ‚xâ‚‚ coefficient:", weights[0][4]);
console.log("xâ‚‚Â² coefficient:", weights[0][5]);
```

</details>

<details>
<summary><b><code>getNormalizationStats()</code></b> - Get normalization statistics</summary>

```typescript
getNormalizationStats(): NormalizationStats
```

**Returns:** `NormalizationStats`

```typescript
interface NormalizationStats {
  min: number[]; // Minimum values per feature
  max: number[]; // Maximum values per feature
  mean: number[]; // Mean values per feature
  std: number[]; // Standard deviation per feature
  count: number; // Number of samples processed
}
```

**Example:**

```typescript
const stats = model.getNormalizationStats();

stats.min.forEach((min, i) => {
  console.log(
    `Feature ${i}: range [${min.toFixed(2)}, ${stats.max[i].toFixed(2)}]`,
  );
  console.log(
    `  Mean: ${stats.mean[i].toFixed(2)}, Std: ${stats.std[i].toFixed(2)}`,
  );
});
```

</details>

<details>
<summary><b><code>reset()</code></b> - Reset model to initial state</summary>

```typescript
reset(): void
```

Clears all learned weights, statistics, and normalization data. Configuration is
preserved.

**Example:**

```typescript
// Reset when you want to start fresh
model.reset();

// Configuration remains the same
// Can immediately start training again
model.fitOnline({
  xCoordinates: newData.x,
  yCoordinates: newData.y,
});
```

</details>

### Configuration Builder

```typescript
class ConfigurationBuilder {
  withPolynomialDegree(degree: number): ConfigurationBuilder;
  withNormalization(enabled: boolean): ConfigurationBuilder;
  withNormalizationMethod(
    method: "none" | "min-max" | "z-score",
  ): ConfigurationBuilder;
  withLearningRate(rate: number): ConfigurationBuilder;
  withLearningRateDecay(decay: number): ConfigurationBuilder;
  withMomentum(momentum: number): ConfigurationBuilder;
  withRegularization(regularization: number): ConfigurationBuilder;
  withGradientClipValue(clipValue: number): ConfigurationBuilder;
  withConfidenceLevel(level: number): ConfigurationBuilder;
  withBatchSize(size: number): ConfigurationBuilder;
  build(): Readonly<IConfiguration>;
}
```

**Fluent API Example:**

```typescript
const config = new ConfigurationBuilder()
  .withPolynomialDegree(3)
  .withLearningRate(0.005)
  .withLearningRateDecay(0.9995)
  .withMomentum(0.95)
  .withNormalizationMethod("z-score")
  .withRegularization(0.0001)
  .withGradientClipValue(0.5)
  .withConfidenceLevel(0.99)
  .withBatchSize(1)
  .build();
```

### Interfaces

<details>
<summary><b>Complete Interface Definitions</b></summary>

```typescript
interface IConfiguration {
  polynomialDegree: number;
  enableNormalization: boolean;
  normalizationMethod: "none" | "min-max" | "z-score";
  learningRate: number;
  learningRateDecay: number;
  momentum: number;
  regularization: number;
  gradientClipValue: number;
  confidenceLevel: number;
  batchSize: number;
}

interface SinglePrediction {
  predicted: number[];
  lowerBound: number[];
  upperBound: number[];
  standardError: number[];
}

interface PredictionResult {
  predictions: SinglePrediction[];
  confidenceLevel: number;
  rSquared: number;
  rmse: number;
  sampleCount: number;
  isModelReady: boolean;
}

interface ModelSummary {
  isInitialized: boolean;
  inputDimension: number;
  outputDimension: number;
  polynomialDegree: number;
  polynomialFeatureCount: number;
  sampleCount: number;
  rSquared: number;
  rmse: number;
  normalizationEnabled: boolean;
  normalizationMethod: string;
}

interface NormalizationStats {
  min: number[];
  max: number[];
  mean: number[];
  std: number[];
  count: number;
}
```

</details>

---

## âš™ï¸ Parameter Optimization Guide

### 1. `polynomialDegree` ğŸ“

> **Controls the complexity of the model by determining the highest power of
> features**

| Property    | Value                           |
| ----------- | ------------------------------- |
| **Type**    | `number`                        |
| **Default** | `2`                             |
| **Range**   | `[1, âˆ)`                        |
| **Impact**  | Model complexity, feature count |

**ğŸ“Š Visual Guide:**

```
Degree 1 (Linear):        y = a + bxâ‚ + cxâ‚‚
                          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                          Features: [1, xâ‚, xâ‚‚]
                          
Degree 2 (Quadratic):     y = a + bxâ‚ + cxâ‚‚ + dxâ‚Â² + exâ‚xâ‚‚ + fxâ‚‚Â²
                          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                          Features: [1, xâ‚, xâ‚‚, xâ‚Â², xâ‚xâ‚‚, xâ‚‚Â²]
                          
Degree 3 (Cubic):         y = ... + gxâ‚Â³ + hxâ‚Â²xâ‚‚ + ixâ‚xâ‚‚Â² + jxâ‚‚Â³
                          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                          Features: [1, xâ‚, xâ‚‚, xâ‚Â², xâ‚xâ‚‚, xâ‚‚Â², xâ‚Â³, ...]
```

**ğŸ¯ Choosing the Right Degree:**

| Scenario             | Recommended | Rationale                          |
| -------------------- | :---------: | ---------------------------------- |
| Linear relationships |      1      | Simple, fast, prevents overfitting |
| Mild curvature       |      2      | Captures parabolic patterns        |
| Complex curves       |      3      | Good balance of flexibility        |
| Highly complex data  |     4-5     | Use with regularization            |
| Real-time systems    |     1-2     | Lower computational cost           |

**âš ï¸ Warning: Feature Explosion**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Feature Count Growth (2 input dimensions)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Degree  â”‚ Feature Countâ”‚ Growth Visualization               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    1    â”‚      3       â”‚ â–ˆâ–ˆâ–ˆ                                â”‚
â”‚    2    â”‚      6       â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             â”‚
â”‚    3    â”‚     10       â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         â”‚
â”‚    4    â”‚     15       â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    â”‚
â”‚    5    â”‚     21       â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              â”‚
â”‚    6    â”‚     28       â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ’¡ Best Practices:**

```typescript
// âœ… Start low, increase if needed
const model1 = new MultivariatePolynomialRegression({ polynomialDegree: 2 });

// âœ… Higher degree with regularization
const model2 = new MultivariatePolynomialRegression({
  polynomialDegree: 4,
  regularization: 0.01, // Prevent overfitting
});

// âŒ Avoid: High degree without regularization
const model3 = new MultivariatePolynomialRegression({
  polynomialDegree: 6,
  regularization: 0, // Will likely overfit!
});
```

---

### 2. `learningRate` ğŸ“ˆ

> **Controls how much weights are updated in response to the estimated error**

| Property    | Value                        |
| ----------- | ---------------------------- |
| **Type**    | `number`                     |
| **Default** | `0.01`                       |
| **Range**   | `(0, 1]`                     |
| **Impact**  | Convergence speed, stability |

**ğŸ“Š Visual Effect:**

```
Learning Rate Effect on Convergence:
                                            
    Loss â”‚     Î· = 0.5 (too high)           
         â”‚    â•±â•²    â•±â•²                      
         â”‚   â•±  â•²  â•±  â•²  â† Oscillates!      
         â”‚  â•±    â•²â•±    â•²                    
         â”‚ â•±            â•²                   
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ iterations    
                                            
    Loss â”‚     Î· = 0.01 (good)              
         â”‚ â•²                                
         â”‚  â•²                               
         â”‚   â•²__                            
         â”‚      â•²___________  â† Converges   
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ iterations    
                                            
    Loss â”‚     Î· = 0.0001 (too low)         
         â”‚ â•²                                
         â”‚  â•²                               
         â”‚   â•²                              
         â”‚    â•²_____  â† Too slow!           
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ iterations
```

**ğŸ¯ Choosing the Right Rate:**

| Scenario               |  Recommended  | Rationale                |
| ---------------------- | :-----------: | ------------------------ |
| Default / Unknown data |     0.01      | Good starting point      |
| Normalized data        |  0.01 - 0.1   | Can use higher rates     |
| Unnormalized data      | 0.001 - 0.01  | Prevents instability     |
| High polynomial degree | 0.001 - 0.005 | More sensitive gradients |
| Streaming data         |  0.01 - 0.05  | Adapt quickly to changes |
| Stable patterns        | 0.001 - 0.01  | Precise convergence      |

**ğŸ’¡ Examples:**

```typescript
// Standard usage
const model1 = new MultivariatePolynomialRegression({
  learningRate: 0.01,
});

// Fast adaptation for streaming data
const model2 = new MultivariatePolynomialRegression({
  learningRate: 0.05,
  learningRateDecay: 0.999, // Will decrease over time
});

// Careful learning for complex models
const model3 = new MultivariatePolynomialRegression({
  polynomialDegree: 4,
  learningRate: 0.001, // Lower rate for stability
  momentum: 0.95, // Compensate with higher momentum
});
```

**ğŸ” Diagnostic Tips:**

```typescript
// Monitor training progress
function trainWithDiagnostics(model, data) {
  const batchSize = 10;

  for (let i = 0; i < data.x.length; i += batchSize) {
    const batch = {
      xCoordinates: data.x.slice(i, i + batchSize),
      yCoordinates: data.y.slice(i, i + batchSize),
    };

    model.fitOnline(batch);

    const summary = model.getModelSummary();
    console.log(`Batch ${i / batchSize}: RMSE = ${summary.rmse.toFixed(6)}`);

    // âš ï¸ Warning signs:
    // - RMSE increasing: learning rate too high
    // - RMSE decreasing very slowly: learning rate too low
    // - RMSE oscillating: learning rate too high
  }
}
```

---

### 3. `learningRateDecay` ğŸ“‰

> **Multiplier applied to learning rate after each sample for gradual
> annealing**

| Property    | Value                                |
| ----------- | ------------------------------------ |
| **Type**    | `number`                             |
| **Default** | `0.999`                              |
| **Range**   | `(0, 1]`                             |
| **Impact**  | Long-term stability, final precision |

**ğŸ“Š Decay Visualization:**

```
Learning Rate Over Time (initial Î· = 0.01):

    Î·   â”‚
  0.01  â”‚â—
        â”‚ â—                                decay = 1.0 (no decay)
        â”‚  â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
        â”‚
 0.005  â”‚   â—                              decay = 0.999
        â”‚    â—â—                            (slow decay)
        â”‚      â—â—â—                         
        â”‚         â—â—â—â—â—â—                   
 0.001  â”‚                â—â—â—â—â—â—â—â—â—â—â—â—â—â—    
        â”‚
        â”‚      â—                           decay = 0.99
0.0001  â”‚       â—â—                         (fast decay)
        â”‚         â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—   
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ samples
            100   500   1000  2000  5000
```

**ğŸ¯ Effective Learning Rate After N Samples:**

$$\eta_N = \eta_0 \times \text{decay}^N$$

| Samples | decay=1.0 | decay=0.999 | decay=0.99 | decay=0.9 |
| :-----: | :-------: | :---------: | :--------: | :-------: |
|   100   |   0.01    |   0.00905   |  0.00366   | 0.000027  |
|   500   |   0.01    |   0.00606   |  0.00007   |    ~0     |
|  1000   |   0.01    |   0.00368   |     ~0     |    ~0     |
|  5000   |   0.01    |   0.00067   |     ~0     |    ~0     |

**ğŸ’¡ Choosing Decay Rate:**

```typescript
// For short training (< 500 samples)
const shortTraining = new ConfigurationBuilder()
  .withLearningRate(0.01)
  .withLearningRateDecay(0.995) // Faster decay
  .build();

// For medium training (500-5000 samples)
const mediumTraining = new ConfigurationBuilder()
  .withLearningRate(0.01)
  .withLearningRateDecay(0.999) // Default, good balance
  .build();

// For long training (> 5000 samples)
const longTraining = new ConfigurationBuilder()
  .withLearningRate(0.01)
  .withLearningRateDecay(0.9999) // Very slow decay
  .build();

// For continuous streaming (never stops)
const streaming = new ConfigurationBuilder()
  .withLearningRate(0.001)
  .withLearningRateDecay(1.0) // No decay - always adaptive
  .build();
```

---

### 4. `momentum` ğŸƒ

> **Coefficient for velocity accumulation to accelerate convergence and reduce
> oscillation**

| Property    | Value                         |
| ----------- | ----------------------------- |
| **Type**    | `number`                      |
| **Default** | `0.9`                         |
| **Range**   | `[0, 1)`                      |
| **Impact**  | Convergence speed, smoothness |

**ğŸ“Š Understanding Momentum:**

```
Without Momentum (Î¼ = 0):        With Momentum (Î¼ = 0.9):
                                 
    â—â”€â”€â”€â†’                            â—â”€â”€â”€â†’
        â”‚                                 â”‚
        â†“                                 â†“
    â†â”€â”€â”€â—                            â†â”€â”€â”€â—â”€â”€â”€â†’ (accumulates velocity)
        â”‚                                      â”‚
        â†“                                      â†“
    â—â”€â”€â”€â†’                                  â—â”€â”€â”€â†’â”€â”€â”€â†’ (builds speed)
        â”‚                                           â”‚
        â†“                                           â†“
                                                    â˜… (reaches faster)
                                 
  Zig-zag path to minimum       Smooth acceleration to minimum
```

**ğŸ”¬ The Physics Analogy:**

```
Think of a ball rolling down a hill:

Î¼ = 0.0: Ball stops immediately when slope changes
         â”œâ”€â”€ New direction each step
         â””â”€â”€ Easily trapped in small valleys

Î¼ = 0.9: Ball has inertia, keeps rolling
         â”œâ”€â”€ Smooths out small bumps
         â”œâ”€â”€ Can escape shallow local minima
         â””â”€â”€ Reaches bottom faster
         
Î¼ = 0.99: Ball is very heavy
          â”œâ”€â”€ Hard to change direction
          â”œâ”€â”€ May overshoot the minimum
          â””â”€â”€ Takes longer to settle
```

**ğŸ¯ Recommended Values:**

| Scenario             | Momentum  | Rationale                   |
| -------------------- | :-------: | --------------------------- |
| Default              |    0.9    | Good balance for most cases |
| Noisy gradients      |   0.95    | Smooths noise               |
| Fast changing data   | 0.5 - 0.7 | Quicker adaptation          |
| Very stable patterns |   0.99    | Faster convergence          |
| No momentum needed   |    0.0    | Pure SGD                    |

**ğŸ’¡ Examples:**

```typescript
// Standard configuration
const standard = new MultivariatePolynomialRegression({
  momentum: 0.9,
});

// For noisy sensor data
const noisyData = new MultivariatePolynomialRegression({
  momentum: 0.95, // High momentum to smooth noise
  learningRate: 0.005, // Lower learning rate for stability
});

// For quickly changing patterns
const adaptiveSGD = new MultivariatePolynomialRegression({
  momentum: 0.5, // Less inertia
  learningRate: 0.02, // Higher learning rate
});

// Pure SGD (no momentum)
const pureSGD = new MultivariatePolynomialRegression({
  momentum: 0.0,
  learningRate: 0.01,
});
```

---

### 5. `normalizationMethod` ğŸ“Š

> **Strategy for scaling input features to improve numerical stability**

| Property    | Value                              |
| ----------- | ---------------------------------- |
| **Type**    | `'none' \| 'min-max' \| 'z-score'` |
| **Default** | `'min-max'`                        |
| **Impact**  | Numerical stability, convergence   |

**ğŸ“Š Comparison:**

```
                  Original Data          Min-Max [0,1]         Z-Score (Î¼=0, Ïƒ=1)
                  
Feature 1:        [100, 200, 300]   â†’   [0, 0.5, 1]      â†’   [-1.22, 0, 1.22]
Feature 2:        [0.1, 0.2, 0.3]   â†’   [0, 0.5, 1]      â†’   [-1.22, 0, 1.22]

Scale difference: 1000x             â†’   Same scale!       â†’   Same scale!
```

**ğŸ”¬ Method Details:**

<table>
<tr>
<th>Method</th>
<th>Formula</th>
<th>Output Range</th>
<th>Best For</th>
</tr>
<tr>
<td><code>none</code></td>
<td>x (unchanged)</td>
<td>Original</td>
<td>Pre-normalized data</td>
</tr>
<tr>
<td><code>min-max</code></td>
<td>(x - min) / (max - min)</td>
<td>[0, 1]</td>
<td>Bounded data, neural networks</td>
</tr>
<tr>
<td><code>z-score</code></td>
<td>(x - Î¼) / Ïƒ</td>
<td>â‰ˆ [-3, 3]</td>
<td>Normally distributed, outliers</td>
</tr>
</table>

**ğŸ¯ When to Use Each:**

```typescript
// Min-Max: When you know the data bounds
// Good for: Images, percentages, bounded sensors
const minMaxModel = new MultivariatePolynomialRegression({
  normalizationMethod: "min-max",
});

// Z-Score: When data may have outliers
// Good for: Financial data, measurements, scientific data
const zScoreModel = new MultivariatePolynomialRegression({
  normalizationMethod: "z-score",
});

// None: When data is already normalized
// Good for: Pre-processed data, unit-normalized vectors
const noNormModel = new MultivariatePolynomialRegression({
  normalizationMethod: "none",
  enableNormalization: false,
});
```

**âš ï¸ Important Considerations:**

```typescript
// Online learning updates statistics incrementally!
// Statistics adapt as more data arrives

const model = new MultivariatePolynomialRegression({
  normalizationMethod: "min-max",
});

// First batch: min=[0], max=[10]
model.fitOnline({ xCoordinates: [[5]], yCoordinates: [[1]] });

// After more data: min may decrease, max may increase
model.fitOnline({ xCoordinates: [[15]], yCoordinates: [[2]] });
// Now max=[15], normalization adjusts accordingly

// Check current stats
console.log(model.getNormalizationStats());
```

---

### 6. `regularization` ğŸ›¡ï¸

> **L2 regularization coefficient (lambda) to prevent overfitting**

| Property    | Value                                    |
| ----------- | ---------------------------------------- |
| **Type**    | `number`                                 |
| **Default** | `1e-6`                                   |
| **Range**   | `[0, âˆ)`                                 |
| **Impact**  | Overfitting prevention, weight magnitude |

**ğŸ“Š Effect Visualization:**

```
Without Regularization (Î» = 0):     With Regularization (Î» > 0):

    y â”‚    â—                            y â”‚    â—
      â”‚   â•±â”‚â•²                             â”‚   /â”‚\
      â”‚  â•± â”‚ â•²                            â”‚  / â”‚ \
      â”‚ â•±â— â”‚ â—â•²                           â”‚ /â— â”‚ â—\
      â”‚â•±   â”‚   â•²â—                         â”‚/   â”‚   \â—
      â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â—â”€â”€â”€ x                    â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â—â”€â”€â”€ x
      â”‚    â”‚     â•²                        â”‚    â”‚     \
      â”‚   Overfits every point!           â”‚   Smoother, generalizes better

Weight magnitudes:                    Weight magnitudes:
[1e6, -5e5, 2e4, ...]                [10.2, -5.3, 2.1, ...]
â†‘ Exploding weights                   â†‘ Controlled weights
```

**ğŸ”¬ The Math:**

```
Loss Function:

Without regularization:
  L = Î£(y - Å·)Â²

With L2 regularization:
  L = Î£(y - Å·)Â² + Î» Ã— Î£wÂ²
                   â†‘
                   Penalizes large weights
                   
Gradient modification:
  g = âˆ‚L/âˆ‚w = -2(y-Å·)x + 2Î»w
                          â†‘
                          Weight decay term
```

**ğŸ¯ Choosing Lambda:**

|   Î» Value    | Effect            | Use When                         |
| :----------: | ----------------- | -------------------------------- |
|      0       | No regularization | Simple models, lots of data      |
| 1e-8 to 1e-6 | Very light        | Default, minimal impact          |
| 1e-5 to 1e-4 | Light             | Moderate complexity              |
| 1e-3 to 1e-2 | Moderate          | High polynomial degree           |
|  0.1 to 1.0  | Strong            | Very complex models, sparse data |

**ğŸ’¡ Examples:**

```typescript
// Default (very light regularization)
const default_model = new MultivariatePolynomialRegression({
  regularization: 1e-6,
});

// High-degree polynomial (needs more regularization)
const highDegree = new MultivariatePolynomialRegression({
  polynomialDegree: 5,
  regularization: 0.001, // Stronger regularization
});

// Very limited data
const limitedData = new MultivariatePolynomialRegression({
  regularization: 0.01, // Strong regularization
});

// Lots of clean data
const abundantData = new MultivariatePolynomialRegression({
  regularization: 1e-8, // Minimal regularization
});
```

**ğŸ“ˆ Cross-Validation Strategy:**

```typescript
// Find optimal regularization through experimentation
const lambdaValues = [1e-8, 1e-6, 1e-4, 1e-2, 0.1];
const results: { lambda: number; rmse: number }[] = [];

for (const lambda of lambdaValues) {
  const model = new MultivariatePolynomialRegression({
    regularization: lambda,
  });

  // Train on training set
  model.fitOnline({ xCoordinates: trainX, yCoordinates: trainY });

  // Evaluate on validation set
  const predictions = model.predict({
    futureSteps: 0,
    inputPoints: valX,
  });

  // Calculate validation RMSE
  const rmse = calculateRMSE(predictions, valY);
  results.push({ lambda, rmse });
}

// Find best lambda
const best = results.reduce((a, b) => a.rmse < b.rmse ? a : b);
console.log(`Best Î»: ${best.lambda}, RMSE: ${best.rmse}`);
```

---

### 7. `gradientClipValue` âœ‚ï¸

> **Maximum absolute gradient value to prevent exploding gradients**

| Property    | Value                                |
| ----------- | ------------------------------------ |
| **Type**    | `number`                             |
| **Default** | `1.0`                                |
| **Range**   | `(0, âˆ)`                             |
| **Impact**  | Numerical stability, training safety |

**ğŸ“Š Visualization:**

```
Without Clipping:                    With Clipping (c = 1.0):

Gradient: [-50, 100, -30, 200]      Gradient: [-50, 100, -30, 200]
              â†“                                      â†“
         EXPLODE! ğŸ’¥                         clip to [-1, 1]
              â†“                                      â†“
    Weights go crazy                 Gradient: [-1, 1, -1, 1]
    Model diverges                            â†“
                                        Stable update
                                        Model converges
```

**ğŸ”¬ The Clipping Operation:**

```typescript
// For each gradient value g:
if (g > clipValue) g = clipValue;
if (g < -clipValue) g = -clipValue;

// Example:
gradients = [-2.5, 0.3, 5.0, -0.1];
clipValue = 1.0;
// After clipping:
gradients = [-1.0, 0.3, 1.0, -0.1];
```

**ğŸ¯ Choosing Clip Value:**

| Scenario            | Clip Value | Rationale               |
| ------------------- | :--------: | ----------------------- |
| Default             |    1.0     | Safe for most cases     |
| Normalized inputs   | 1.0 - 5.0  | Gradients usually small |
| Unnormalized inputs | 0.1 - 1.0  | Tighter control         |
| High learning rate  | 0.5 - 1.0  | Prevent overshooting    |
| Complex models      | 0.5 - 2.0  | Extra stability         |

**ğŸ’¡ Examples:**

```typescript
// Standard configuration
const standard = new MultivariatePolynomialRegression({
  gradientClipValue: 1.0,
});

// Extra stable training
const stable = new MultivariatePolynomialRegression({
  gradientClipValue: 0.5,
  learningRate: 0.01,
});

// Allow larger gradients (when you're sure data is clean)
const relaxed = new MultivariatePolynomialRegression({
  gradientClipValue: 5.0,
  normalizationMethod: "z-score", // Ensures bounded inputs
});
```

**âš ï¸ Signs You Need Lower Clip Value:**

```typescript
// If you see these issues, try lowering gradientClipValue:

model.fitOnline({ xCoordinates: X, yCoordinates: Y });
const summary = model.getModelSummary();

if (isNaN(summary.rmse)) {
  console.log("âš ï¸ NaN detected! Lower gradientClipValue");
}

if (summary.rmse > 1e10) {
  console.log("âš ï¸ RMSE exploding! Lower gradientClipValue");
}

const weights = model.getWeights();
if (weights.some((row) => row.some((w) => Math.abs(w) > 1e6))) {
  console.log("âš ï¸ Weights exploding! Lower gradientClipValue");
}
```

---

### 8. `confidenceLevel` ğŸ¯

> **Confidence level for prediction intervals (e.g., 0.95 for 95% confidence)**

| Property    | Value                     |
| ----------- | ------------------------- |
| **Type**    | `number`                  |
| **Default** | `0.95`                    |
| **Range**   | `(0, 1)`                  |
| **Impact**  | Prediction interval width |

**ğŸ“Š Visualization:**

```
Confidence Interval Width at Different Levels:

    y â”‚
      â”‚           â”Œâ”€â”€â”€ 99% CI (widest)
      â”‚        â•­â”€â”€â”´â”€â”€â•®
      â”‚     â•­â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â•®
      â”‚  â•­â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â•®  â† 95% CI
      â”‚  â”‚     â•­â”€â”€â”€â•®       â”‚
      â”‚  â”‚  â•­â”€â”€â”´â”€â”€â”€â”´â”€â”€â•®    â”‚  â† 90% CI
      â”‚  â”‚  â”‚    â—    â”‚    â”‚  â† Prediction
      â”‚  â”‚  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯    â”‚
      â”‚  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ x
      
Higher confidence = Wider interval = More certain to contain true value
```

**ğŸ”¬ Critical Values:**

| Confidence Level | Z-value (large n) | Meaning                  |
| :--------------: | :---------------: | ------------------------ |
|       80%        |       1.28        | "Probably right"         |
|       90%        |       1.645       | "Likely right"           |
|       95%        |       1.96        | "Very likely right"      |
|       99%        |       2.576       | "Almost certainly right" |

**ğŸ¯ Choosing Confidence Level:**

| Application          | Recommended | Rationale              |
| -------------------- | :---------: | ---------------------- |
| Exploratory analysis | 0.80 - 0.90 | Tighter bounds         |
| General reporting    |    0.95     | Standard in statistics |
| Safety-critical      |    0.99     | Conservative bounds    |
| Financial risk       | 0.95 - 0.99 | Regulatory compliance  |

**ğŸ’¡ Examples:**

```typescript
// Standard 95% confidence
const standard = new MultivariatePolynomialRegression({
  confidenceLevel: 0.95,
});

const result = standard.predict({ futureSteps: 3 });
// result.predictions[0].lowerBound  â†’ Lower 95% CI
// result.predictions[0].upperBound  â†’ Upper 95% CI

// Higher confidence for safety-critical applications
const safetyCritical = new MultivariatePolynomialRegression({
  confidenceLevel: 0.99,
});

// Lower confidence for quick estimates
const quickEstimate = new MultivariatePolynomialRegression({
  confidenceLevel: 0.80,
});
```

**ğŸ“ˆ Using Confidence Intervals:**

```typescript
const model = new MultivariatePolynomialRegression({
  confidenceLevel: 0.95,
});

model.fitOnline({ xCoordinates: trainingX, yCoordinates: trainingY });

const result = model.predict({ futureSteps: 5 });

result.predictions.forEach((pred, i) => {
  console.log(`
  Step ${i + 1}:
    Predicted: ${pred.predicted[0].toFixed(2)}
    95% CI: [${pred.lowerBound[0].toFixed(2)}, ${pred.upperBound[0].toFixed(2)}]
    Margin: Â±${(pred.upperBound[0] - pred.predicted[0]).toFixed(2)}
  `);

  // Check if interval is meaningful
  const width = pred.upperBound[0] - pred.lowerBound[0];
  if (width > pred.predicted[0]) {
    console.log("  âš ï¸ Wide interval - prediction uncertain");
  }
});
```

---

### 9. `batchSize` ğŸ“¦

> **Number of samples to process together (currently used for future batch
> processing)**

| Property    | Value                         |
| ----------- | ----------------------------- |
| **Type**    | `number`                      |
| **Default** | `1`                           |
| **Range**   | `[1, âˆ)`                      |
| **Impact**  | Reserved for batch processing |

**ğŸ“ Note:** The current implementation processes samples one at a time
regardless of this setting, but the parameter is reserved for future mini-batch
SGD support.

**ğŸ’¡ Current Usage:**

```typescript
// Currently, batchSize doesn't change behavior
// Samples are always processed one at a time
const model = new MultivariatePolynomialRegression({
  batchSize: 1, // Default and recommended for now
});
```

---

## ğŸ® Real-World Examples

### Example 1: Stock Price Prediction

```typescript
import {
  ConfigurationBuilder,
  MultivariatePolynomialRegression,
} from "jsr:@hviana/polynomial-regression";

// Configuration optimized for financial data
const config = new ConfigurationBuilder()
  .withPolynomialDegree(2) // Capture non-linear trends
  .withNormalizationMethod("z-score") // Handle outliers
  .withLearningRate(0.005) // Conservative learning
  .withMomentum(0.9) // Smooth updates
  .withRegularization(0.0001) // Prevent overfitting
  .withConfidenceLevel(0.95) // Standard confidence
  .build();

const model = new MultivariatePolynomialRegression(config);

// Historical data: [open, high, low, volume] -> [close]
const historicalData = {
  xCoordinates: [
    [150.00, 152.50, 149.00, 1000000],
    [152.00, 155.00, 151.00, 1200000],
    [154.00, 156.50, 153.00, 1100000],
    [156.00, 158.00, 155.00, 900000],
    [157.50, 160.00, 156.50, 1300000],
  ],
  yCoordinates: [
    [151.50],
    [154.00],
    [155.50],
    [157.00],
    [159.00],
  ],
};

// Train incrementally
model.fitOnline(historicalData);

// Predict next day's close
const todaysData = [[158.00, 161.00, 157.00, 1100000]];
const prediction = model.predict({
  futureSteps: 0,
  inputPoints: todaysData,
});

console.log(`
ğŸ“ˆ Stock Price Prediction
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Today's Open:    $${todaysData[0][0]}
Predicted Close: $${prediction.predictions[0].predicted[0].toFixed(2)}
95% CI:          [$${prediction.predictions[0].lowerBound[0].toFixed(2)}, 
                  $${prediction.predictions[0].upperBound[0].toFixed(2)}]
Model RÂ²:        ${prediction.rSquared.toFixed(4)}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
`);
```

### Example 2: Sensor Calibration

```typescript
import { MultivariatePolynomialRegression } from "jsr:@hviana/polynomial-regression";

// Calibrate a temperature sensor with non-linear response
// Input: [raw_reading, ambient_temp, humidity]
// Output: [actual_temperature]

const calibrationModel = new MultivariatePolynomialRegression({
  polynomialDegree: 3, // Capture sensor non-linearity
  normalizationMethod: "min-max", // Bounded sensor values
  learningRate: 0.01,
  regularization: 1e-5,
});

// Calibration data from reference sensor
const calibrationData = {
  xCoordinates: [
    [100, 20, 45], // raw=100 at 20Â°C, 45% humidity
    [150, 25, 50],
    [200, 30, 55],
    [250, 35, 60],
    [300, 40, 65],
    [350, 45, 70],
    [400, 50, 75],
  ],
  yCoordinates: [
    [22.1], // Actual temperature from reference
    [26.3],
    [31.0],
    [36.2],
    [41.5],
    [47.1],
    [52.8],
  ],
};

calibrationModel.fitOnline(calibrationData);

// Real-time calibration function
function calibratedTemperature(
  rawReading: number,
  ambientTemp: number,
  humidity: number,
): { temperature: number; uncertainty: number } {
  const result = calibrationModel.predict({
    futureSteps: 0,
    inputPoints: [[rawReading, ambientTemp, humidity]],
  });

  return {
    temperature: result.predictions[0].predicted[0],
    uncertainty: result.predictions[0].standardError[0],
  };
}

// Use calibrated sensor
const reading = calibratedTemperature(275, 37, 62);
console.log(`
ğŸŒ¡ï¸ Calibrated Sensor Reading
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Temperature: ${reading.temperature.toFixed(1)}Â°C
Uncertainty: Â±${reading.uncertainty.toFixed(2)}Â°C
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
`);
```

### Example 3: Real-Time IoT Data Processing

```typescript
import { MultivariatePolynomialRegression } from "jsr:@hviana/polynomial-regression";

// Configure for streaming IoT data
const iotModel = new MultivariatePolynomialRegression({
  polynomialDegree: 2,
  learningRate: 0.02, // Higher for adaptation
  learningRateDecay: 1.0, // No decay - continuous learning
  momentum: 0.8, // Moderate momentum
  normalizationMethod: "z-score",
  gradientClipValue: 1.0,
});

// Simulated IoT data stream
interface SensorPacket {
  timestamp: number;
  temperature: number;
  pressure: number;
  vibration: number;
  powerConsumption: number; // Target to predict
}

async function processIoTStream(stream: AsyncIterable<SensorPacket>) {
  let packetCount = 0;

  for await (const packet of stream) {
    // Features: [temp, pressure, vibration]
    // Target: [power consumption]
    const features = [packet.temperature, packet.pressure, packet.vibration];
    const target = [packet.powerConsumption];

    // Update model with new data
    iotModel.fitOnline({
      xCoordinates: [features],
      yCoordinates: [target],
    });

    packetCount++;

    // Log progress every 100 packets
    if (packetCount % 100 === 0) {
      const summary = iotModel.getModelSummary();
      console.log(`
ğŸ“¡ IoT Model Update [Packet #${packetCount}]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
RÂ²:   ${summary.rSquared.toFixed(4)}
RMSE: ${summary.rmse.toFixed(4)}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      `);
    }

    // Predict next power consumption
    if (packetCount > 10) { // Wait for model to warm up
      const prediction = iotModel.predict({ futureSteps: 1 });

      // Trigger alert if high consumption predicted
      if (prediction.predictions[0].predicted[0] > 1000) {
        console.log("âš ï¸ HIGH POWER CONSUMPTION PREDICTED!");
      }
    }
  }
}
```

---

## ğŸ“Š Performance Optimization

### Memory Efficiency

The library is designed for **constant memory usage** regardless of training
data size:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MEMORY ARCHITECTURE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Traditional Batch Learning:        Online Learning:        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Store ALL data        â”‚          â”‚ Process ONE point â”‚  â”‚
â”‚  â”‚ [xâ‚,xâ‚‚,...,xâ‚™]        â”‚          â”‚ at a time         â”‚  â”‚
â”‚  â”‚ [yâ‚,yâ‚‚,...,yâ‚™]        â”‚          â”‚                   â”‚  â”‚
â”‚  â”‚                       â”‚          â”‚ â”Œâ”€â”€â”€â”             â”‚  â”‚
â”‚  â”‚ Memory: O(n)          â”‚          â”‚ â”‚ xáµ¢â”‚ â†’ Update    â”‚  â”‚
â”‚  â”‚ â†‘ Grows with data!    â”‚          â”‚ â””â”€â”€â”€â”˜   weights   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚                   â”‚  â”‚
â”‚                                     â”‚ Memory: O(1)      â”‚  â”‚
â”‚                                     â”‚ â†‘ Constant!       â”‚  â”‚
â”‚                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Memory Usage by Component:**

| Component  | Memory                    | Notes                  |
| ---------- | ------------------------- | ---------------------- |
| Weights    | O(output Ã— features)      | Main model storage     |
| Velocity   | O(output Ã— features)      | For momentum           |
| Buffers    | O(features + output)      | Reusable, preallocated |
| Statistics | O(input_dim + output_dim) | Running stats          |
| **Total**  | **O(output Ã— features)**  | **Does not grow!**     |

### Computational Efficiency

```typescript
// Hot path optimizations:

// 1. Preallocated typed arrays (no GC pressure)
private featureBuffer: Float64Array;

// 2. Loop unrolling for dot products
for (; i < unrolledLen; i += 4) {
  result += a[i] * b[i] +
            a[i+1] * b[i+1] +
            a[i+2] * b[i+2] +
            a[i+3] * b[i+3];
}

// 3. Object pooling for array reuse
const arr = matrixOps.acquireArray(size);
// ... use array ...
matrixOps.releaseArray(arr);

// 4. Inline power computation (faster than Math.pow)
let power = 1.0;
for (let e = 0; e < exp; e++) {
  power *= base;
}
```

**Time Complexity per Operation:**

| Operation              | Complexity              | Notes      |
| ---------------------- | ----------------------- | ---------- |
| `fitOnline` (1 sample) | O(output Ã— features)    | Per sample |
| `predict` (1 point)    | O(output Ã— features)    | Per point  |
| Feature generation     | O(features Ã— input_dim) |            |
| Normalization          | O(input_dim)            |            |
| Weight update          | O(features)             | Per output |

### Recommended Configurations by Use Case

<details>
<summary><b>ğŸš€ Low Latency / Real-Time</b></summary>

```typescript
const realTimeConfig = new ConfigurationBuilder()
  .withPolynomialDegree(1) // Linear = fastest
  .withNormalization(false) // Skip normalization
  .withLearningRate(0.01)
  .withMomentum(0.9)
  .withLearningRateDecay(1.0) // No decay overhead
  .build();
```

</details>

<details>
<summary><b>ğŸ’¾ Memory Constrained</b></summary>

```typescript
const memoryConfig = new ConfigurationBuilder()
  .withPolynomialDegree(2) // Keep degree low
  .withNormalization(true) // Min-max (no std storage needed)
  .withNormalizationMethod("min-max")
  .build();

// Feature count for degree 2, 5 inputs: 21
// Feature count for degree 3, 5 inputs: 56  â† 2.7x more memory!
```

</details>

<details>
<summary><b>ğŸ¯ Maximum Accuracy</b></summary>

```typescript
const accuracyConfig = new ConfigurationBuilder()
  .withPolynomialDegree(3)
  .withNormalizationMethod("z-score")
  .withLearningRate(0.005)
  .withLearningRateDecay(0.9995)
  .withMomentum(0.95)
  .withRegularization(0.0001)
  .withGradientClipValue(0.5)
  .withConfidenceLevel(0.99)
  .build();
```

</details>

<details>
<summary><b>ğŸ“¡ Streaming Data</b></summary>

```typescript
const streamingConfig = new ConfigurationBuilder()
  .withPolynomialDegree(2)
  .withLearningRate(0.02) // Higher to adapt quickly
  .withLearningRateDecay(1.0) // Never stops learning
  .withMomentum(0.7) // Less inertia
  .withNormalizationMethod("z-score") // Handle outliers
  .build();
```

</details>

---

## ğŸ”§ Advanced Usage

### Custom Normalization Strategies

```typescript
import {
  INormalizationStatsInternal,
  INormalizationStrategy,
} from "jsr:@hviana/polynomial-regression";

// Implement your own normalization strategy
class RobustScalerStrategy implements INormalizationStrategy {
  normalize(
    value: number,
    index: number,
    stats: INormalizationStatsInternal,
  ): number {
    // Use median and IQR instead of mean and std
    // This is more robust to outliers
    const median = stats.mean[index]; // Approximate
    const iqr = stats.std[index] * 1.35; // Approximate IQR

    if (iqr < 1e-10) return 0;
    return (value - median) / iqr;
  }

  denormalize(
    value: number,
    index: number,
    stats: INormalizationStatsInternal,
  ): number {
    const median = stats.mean[index];
    const iqr = stats.std[index] * 1.35;
    return value * iqr + median;
  }
}
```

### Model Serialization

```typescript
interface SerializedModel {
  config: IConfiguration;
  weights: number[][];
  stats: NormalizationStats;
  summary: ModelSummary;
}

function serializeModel(model: MultivariatePolynomialRegression): string {
  const serialized: SerializedModel = {
    config: model["config"], // Access private config
    weights: model.getWeights(),
    stats: model.getNormalizationStats(),
    summary: model.getModelSummary(),
  };
  return JSON.stringify(serialized);
}

function deserializeModel(json: string): MultivariatePolynomialRegression {
  const data: SerializedModel = JSON.parse(json);

  const model = new MultivariatePolynomialRegression(data.config);

  // Note: Full deserialization would require additional API methods
  // This is a simplified version for demonstration

  return model;
}

// Save model
const modelJson = serializeModel(trainedModel);
localStorage.setItem("my-model", modelJson);

// Load model
const loadedJson = localStorage.getItem("my-model")!;
const loadedModel = deserializeModel(loadedJson);
```

### Monitoring Training Progress

```typescript
class TrainingMonitor {
  private history: {
    epoch: number;
    rmse: number;
    rSquared: number;
    learningRate: number;
  }[] = [];

  log(model: MultivariatePolynomialRegression, epoch: number) {
    const summary = model.getModelSummary();

    this.history.push({
      epoch,
      rmse: summary.rmse,
      rSquared: summary.rSquared,
      learningRate: model["currentLearningRate"],
    });

    this.printProgress();
  }

  private printProgress() {
    const latest = this.history[this.history.length - 1];
    const prev = this.history[this.history.length - 2];

    const rmseChange = prev
      ? ((latest.rmse - prev.rmse) / prev.rmse * 100).toFixed(2)
      : "N/A";

    console.log(`
Epoch ${latest.epoch}:
  RMSE:     ${latest.rmse.toFixed(6)} (${rmseChange}%)
  RÂ²:       ${latest.rSquared.toFixed(4)}
  LR:       ${latest.learningRate.toFixed(6)}
    `);
  }

  getHistory() {
    return [...this.history];
  }

  plotAscii(): string {
    const width = 50;
    const height = 10;

    const rmseValues = this.history.map((h) => h.rmse);
    const maxRmse = Math.max(...rmseValues);
    const minRmse = Math.min(...rmseValues);

    let plot = "\n  RMSE over epochs:\n  ";
    plot += "â”€".repeat(width + 2) + "\n";

    for (let row = height; row >= 0; row--) {
      const threshold = minRmse + (maxRmse - minRmse) * row / height;
      let line = row === height
        ? maxRmse.toFixed(3).padStart(7)
        : row === 0
        ? minRmse.toFixed(3).padStart(7)
        : "       ";

      line += "â”‚";

      for (let col = 0; col < width; col++) {
        const idx = Math.floor(col * this.history.length / width);
        if (idx < this.history.length && rmseValues[idx] >= threshold) {
          line += "â–ˆ";
        } else {
          line += " ";
        }
      }

      plot += line + "\n";
    }

    plot += "       â””" + "â”€".repeat(width) + "\n";
    plot += "        0" + " ".repeat(width - 10) + "epochs";

    return plot;
  }
}

// Usage
const monitor = new TrainingMonitor();
const model = new MultivariatePolynomialRegression();

for (let epoch = 0; epoch < data.x.length; epoch++) {
  model.fitOnline({
    xCoordinates: [data.x[epoch]],
    yCoordinates: [data.y[epoch]],
  });

  if (epoch % 10 === 0) {
    monitor.log(model, epoch);
  }
}

console.log(monitor.plotAscii());
```

---

## ğŸ› Troubleshooting

<details>
<summary><b>â“ Model returns NaN predictions</b></summary>

**Possible Causes:**

1. Learning rate too high
2. Gradient explosion
3. Input contains NaN or Infinity

**Solutions:**

```typescript
// 1. Lower learning rate
const model = new MultivariatePolynomialRegression({
  learningRate: 0.001, // Try 10x smaller
});

// 2. Tighter gradient clipping
const model = new MultivariatePolynomialRegression({
  gradientClipValue: 0.5, // Clip earlier
});

// 3. Validate inputs
function validateInput(x: number[][]): boolean {
  return x.every((row) =>
    row.every((val) =>
      typeof val === "number" &&
      isFinite(val) &&
      !isNaN(val)
    )
  );
}

if (!validateInput(xCoordinates)) {
  throw new Error("Invalid input data");
}
```

</details>

<details>
<summary><b>â“ RÂ² is negative</b></summary>

**Meaning:** Model is worse than simply predicting the mean.

**Possible Causes:**

1. Not enough training data
2. Model not appropriate for data
3. Features not relevant to target

**Solutions:**

```typescript
// 1. Train with more data
// RÂ² becomes meaningful after ~30 samples

// 2. Try different polynomial degree
const model1 = new MultivariatePolynomialRegression({ polynomialDegree: 1 });
const model2 = new MultivariatePolynomialRegression({ polynomialDegree: 2 });
const model3 = new MultivariatePolynomialRegression({ polynomialDegree: 3 });

// Compare RÂ² for each

// 3. Check feature relevance
// Plot features vs target to verify relationships exist
```

</details>

<details>
<summary><b>â“ Training is slow</b></summary>

**Possible Causes:**

1. High polynomial degree
2. Many input dimensions
3. Suboptimal configuration

**Solutions:**

```typescript
// 1. Reduce polynomial degree
const fast = new MultivariatePolynomialRegression({
  polynomialDegree: 2, // vs 4 or 5
});

// 2. Feature selection - use only relevant features
// Before: 10 features, degree 3 = 286 polynomial features
// After: 5 features, degree 3 = 56 polynomial features

// 3. Profile and optimize
console.time("training");
model.fitOnline({ xCoordinates: X, yCoordinates: Y });
console.timeEnd("training");
```

</details>

<details>
<summary><b>â“ Predictions have wide confidence intervals</b></summary>

**Possible Causes:**

1. High residual variance
2. Extrapolating far from training data
3. Not enough training samples

**Solutions:**

```typescript
// 1. Train with more data
// Confidence intervals narrow with âˆšn

// 2. Stay within training data range
const stats = model.getNormalizationStats();
console.log("Training range:", stats.min, "to", stats.max);
// Don't predict far outside this range

// 3. Use lower confidence level (if appropriate)
const model = new MultivariatePolynomialRegression({
  confidenceLevel: 0.90, // Narrower than 0.95
});
```

</details>

<details>
<summary><b>â“ Model overfits (high RÂ² on training, poor on test)</b></summary>

**Possible Causes:**

1. Polynomial degree too high
2. Too little regularization
3. Not enough training data for complexity

**Solutions:**

```typescript
// 1. Lower polynomial degree
const simpler = new MultivariatePolynomialRegression({
  polynomialDegree: 2, // vs 4 or 5
});

// 2. Increase regularization
const regularized = new MultivariatePolynomialRegression({
  regularization: 0.01, // vs 1e-6
});

// 3. Both approaches combined
const balanced = new MultivariatePolynomialRegression({
  polynomialDegree: 3,
  regularization: 0.001,
});
```

</details>

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LIBRARY ARCHITECTURE                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 MultivariatePolynomialRegression                 â”‚   â”‚
â”‚  â”‚                      (Main Orchestrator)                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                          â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚         â”‚                    â”‚                    â”‚                    â”‚
â”‚         â–¼                    â–¼                    â–¼                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  Normalizer â”‚     â”‚  Polynomial â”‚      â”‚   Weight    â”‚             â”‚
â”‚  â”‚             â”‚     â”‚  Feature    â”‚      â”‚   Manager   â”‚             â”‚
â”‚  â”‚ - min-max   â”‚     â”‚  Generator  â”‚      â”‚             â”‚             â”‚
â”‚  â”‚ - z-score   â”‚     â”‚             â”‚      â”‚ - Xavier    â”‚             â”‚
â”‚  â”‚ - none      â”‚     â”‚ - degree n  â”‚      â”‚   init      â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ - all terms â”‚      â”‚ - flat      â”‚             â”‚
â”‚         â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   storage   â”‚             â”‚
â”‚         â”‚                    â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                    â”‚                    â”‚                    â”‚
â”‚         â–¼                    â–¼                    â–¼                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                    TRAINING PIPELINE                         â”‚      â”‚
â”‚  â”‚  x â†’ normalize â†’ poly_features â†’ predict â†’ error â†’ gradient â”‚      â”‚
â”‚  â”‚                                                    â†“         â”‚      â”‚
â”‚  â”‚                              update weights â† momentum â†â”€â”€â”€â”€â”€â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                    â”‚                    â”‚                    â”‚
â”‚         â–¼                    â–¼                    â–¼                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  Gradient   â”‚     â”‚ Prediction  â”‚      â”‚ Statistics  â”‚             â”‚
â”‚  â”‚  Manager    â”‚     â”‚ Engine      â”‚      â”‚ Tracker     â”‚             â”‚
â”‚  â”‚             â”‚     â”‚             â”‚      â”‚             â”‚             â”‚
â”‚  â”‚ - momentum  â”‚     â”‚ - forward   â”‚      â”‚ - RÂ²        â”‚             â”‚
â”‚  â”‚ - clipping  â”‚     â”‚   pass      â”‚      â”‚ - RMSE      â”‚             â”‚
â”‚  â”‚ - velocity  â”‚     â”‚ - conf      â”‚      â”‚ - Welford   â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   intervals â”‚      â”‚   online    â”‚             â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                  UTILITIES & STRATEGIES                      â”‚      â”‚
â”‚  â”‚                                                              â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚      â”‚
â”‚  â”‚  â”‚ Matrix        â”‚  â”‚ Normalizationâ”‚  â”‚Configuration â”‚     â”‚      â”‚
â”‚  â”‚  â”‚ Operations    â”‚  â”‚ Strategies   â”‚  â”‚ Builder      â”‚     â”‚      â”‚
â”‚  â”‚  â”‚               â”‚  â”‚              â”‚  â”‚              â”‚     â”‚      â”‚
â”‚  â”‚  â”‚ - dot product â”‚  â”‚ - Min-Max    â”‚  â”‚ - Fluent API â”‚     â”‚      â”‚
â”‚  â”‚  â”‚ - scalar mult â”‚  â”‚ - Z-Score    â”‚  â”‚ - Validation â”‚     â”‚      â”‚
â”‚  â”‚  â”‚ - array pool  â”‚  â”‚ - None       â”‚  â”‚ - Defaults   â”‚     â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Design Patterns Used:**

| Pattern                  | Where                              | Purpose              |
| ------------------------ | ---------------------------------- | -------------------- |
| **Builder**              | `ConfigurationBuilder`             | Fluent configuration |
| **Strategy**             | Normalization                      | Swappable algorithms |
| **Dependency Injection** | Main class                         | Testability          |
| **Object Pool**          | `MatrixOperations`                 | Memory efficiency    |
| **Facade**               | `MultivariatePolynomialRegression` | Simple API           |

---

## ğŸ“ˆ Benchmarks

**Test Configuration:**

- Node.js v18.x
- 2.6 GHz Intel Core i7
- 16GB RAM

| Operation                  | 2D Input, Degree 2 | 5D Input, Degree 3 | 10D Input, Degree 2 |
| -------------------------- | :----------------: | :----------------: | :-----------------: |
| Feature Count              |         6          |         56         |         66          |
| `fitOnline` (1 sample)     |       0.02ms       |       0.15ms       |       0.18ms        |
| `fitOnline` (1000 samples) |        8ms         |        95ms        |        120ms        |
| `predict` (1 point)        |       0.01ms       |       0.08ms       |       0.10ms        |
| Memory (trained model)     |        ~2KB        |       ~15KB        |        ~20KB        |

**Scaling Analysis:**

```
Training Time vs Polynomial Degree (5D input, 1000 samples):

Time â”‚
 ms  â”‚                                    â—  
200  â”‚                               â—
     â”‚                          â—
150  â”‚                     â—
     â”‚                â—
100  â”‚           â—
     â”‚      â—
 50  â”‚ â—
     â”‚
   0 â”œâ”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”€â”€ degree
       1  2  3  4  5  6  7

Feature counts: 6, 21, 56, 126, 252, 462, 792
```

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. **ğŸ› Report Bugs**
   - Open an issue with a clear description
   - Include reproduction steps
   - Attach sample data if possible

2. **ğŸ’¡ Suggest Features**
   - Open an issue with `[Feature]` prefix
   - Describe the use case
   - Provide examples

3. **ğŸ”§ Submit Pull Requests**
   ```bash
   # Fork and clone the repository
   git clone https://github.com/your-username/multivariate-polynomial-regression.git

   # Create a feature branch
   git checkout -b feature/amazing-feature

   # Make your changes
   # ... code ...

   # Run tests
   npm test

   # Commit with conventional commits
   git commit -m 'feat: add amazing feature'

   # Push and create PR
   git push origin feature/amazing-feature
   ```

4. **ğŸ“– Improve Documentation**
   - Fix typos
   - Add examples
   - Clarify explanations

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file
for details.

```
MIT License

Copyright (c) 2025

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ğŸ™ Acknowledgments

- **Welford's Algorithm** - For numerically stable online variance computation
- **Xavier/Glorot Initialization** - For improved weight initialization
- **TypeScript Community** - For excellent typing support

---

<div align="center">

**â­ Star this repo if you find it useful! â­**

Made with â¤ï¸ for the machine learning community

[Report Bug](https://github.com/your-repo/issues) Â·
[Request Feature](https://github.com/your-repo/issues) Â·
[Documentation](https://your-docs-url.com)

</div>
